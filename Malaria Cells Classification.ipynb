{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "- Read images into numpy array\n",
    "- Save numpy array into files\n",
    "- Mapping targets into int labels\n",
    "- Split data into train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_file):\n",
    "    image = cv2.imread(image_file)\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((50, 50))\n",
    "    image = np.array(image)\n",
    "    return image\n",
    "\n",
    "\n",
    "if os.path.exists(\"Cells.npy\") and os.path.exists(\"Labels.npy\"):\n",
    "    cells = np.load(\"Cells.npy\")\n",
    "    labels = np.load(\"Labels.npy\")\n",
    "else:\n",
    "    Parasitized = [load_image(p) for p in glob.glob(\"./cell_images/cell_images/Parasitized/*.png\")]\n",
    "    Uninfected = [load_image(p) for p in glob.glob(\"./cell_images/cell_images/Uninfected/*.png\")]\n",
    "    cells = np.array(Parasitized + Uninfected)\n",
    "    labels = np.array([0] * len(Parasitized) + [1]*len(Uninfected))\n",
    "    \n",
    "    np.save(\"Cells\", cells)\n",
    "    np.save(\"Labels\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize  data\n",
    "cells = cells / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(cells, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding of y\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "y_test = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the CNN model\n",
    "- 2 convolutional layers and 2 dense layers\n",
    "- Dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(filters=16, kernel_size=2, padding=\"same\", activation=\"relu\", input_shape=(50,50,3)),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=32, kernel_size=2, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=64, kernel_size=2, padding=\"same\", activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(500,activation=\"relu\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(2,activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 50, 50, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 1,164,046\n",
      "Trainable params: 1,164,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "340/340 [==============================] - 3s 10ms/step - loss: 0.4193 - accuracy: 0.7989 - val_loss: 0.2319 - val_accuracy: 0.9303\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.1688 - accuracy: 0.9433 - val_loss: 0.1730 - val_accuracy: 0.9455\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.1459 - accuracy: 0.9524 - val_loss: 0.1592 - val_accuracy: 0.9526\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.1348 - accuracy: 0.9564 - val_loss: 0.1496 - val_accuracy: 0.9542\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.1301 - accuracy: 0.9572 - val_loss: 0.1403 - val_accuracy: 0.9555\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.1211 - accuracy: 0.9598 - val_loss: 0.1324 - val_accuracy: 0.9578\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.1152 - accuracy: 0.9615 - val_loss: 0.1350 - val_accuracy: 0.9587\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.1101 - accuracy: 0.9625 - val_loss: 0.1245 - val_accuracy: 0.9607\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.1022 - accuracy: 0.9643 - val_loss: 0.1364 - val_accuracy: 0.9561\n",
      "Epoch 10/10\n",
      "340/340 [==============================] - 3s 9ms/step - loss: 0.0988 - accuracy: 0.9657 - val_loss: 0.1278 - val_accuracy: 0.9590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f967361be50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with 1/9 of the data as validation dataset\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_split=0.125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Performance\n",
    "- Accuracy\n",
    "- Confusion matrix\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 3ms/step - loss: 0.1177 - accuracy: 0.9579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11773661524057388, 0.9579100012779236]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss, accuracy\n",
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1319,   88],\n",
       "       [  28, 1321]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9579405366207396"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cells.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model without classifier layers\n",
    "model = VGG16(include_top=False, input_shape=(50, 50, 3))\n",
    "# for layer in model.layers:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# add new classifier layers\n",
    "flat1 = Flatten()(model.layers[-1].output)\n",
    "class1 = Dense(512, activation='relu')(flat1)\n",
    "output = Dense(2, activation='softmax')(class1)\n",
    "# define new model\n",
    "model = Model(inputs=model.inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  2/340 [..............................] - ETA: 21s - loss: 22.9587 - accuracy: 0.4531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0490s vs `on_train_batch_end` time: 0.0776s). Check your callbacks.\n",
      "340/340 [==============================] - 44s 129ms/step - loss: 0.4290 - accuracy: 0.8494 - val_loss: 0.1462 - val_accuracy: 0.9536\n",
      "Epoch 2/10\n",
      "340/340 [==============================] - 42s 125ms/step - loss: 0.1381 - accuracy: 0.9574 - val_loss: 0.1344 - val_accuracy: 0.9555\n",
      "Epoch 3/10\n",
      "340/340 [==============================] - 42s 125ms/step - loss: 0.1280 - accuracy: 0.9572 - val_loss: 0.2260 - val_accuracy: 0.9332\n",
      "Epoch 4/10\n",
      "340/340 [==============================] - 42s 124ms/step - loss: 0.1268 - accuracy: 0.9618 - val_loss: 0.1360 - val_accuracy: 0.9536\n",
      "Epoch 5/10\n",
      "340/340 [==============================] - 42s 125ms/step - loss: 0.1134 - accuracy: 0.9629 - val_loss: 0.1268 - val_accuracy: 0.9584\n",
      "Epoch 6/10\n",
      "340/340 [==============================] - 42s 124ms/step - loss: 0.1085 - accuracy: 0.9648 - val_loss: 0.1243 - val_accuracy: 0.9561\n",
      "Epoch 7/10\n",
      "340/340 [==============================] - 42s 124ms/step - loss: 0.1165 - accuracy: 0.9619 - val_loss: 0.1670 - val_accuracy: 0.9474\n",
      "Epoch 8/10\n",
      "340/340 [==============================] - 42s 124ms/step - loss: 0.1050 - accuracy: 0.9647 - val_loss: 0.1893 - val_accuracy: 0.9400\n",
      "Epoch 9/10\n",
      "340/340 [==============================] - 42s 125ms/step - loss: 0.1122 - accuracy: 0.9636 - val_loss: 0.1297 - val_accuracy: 0.9523\n",
      "Epoch 10/10\n",
      "194/340 [================>.............] - ETA: 17s - loss: 0.1131 - accuracy: 0.9638"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=10, verbose=1, validation_split=0.125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 26ms/step - loss: 0.1322 - accuracy: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.13218945264816284, 0.956095814704895]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loss, Acc\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1316,   91],\n",
       "       [  30, 1319]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9561435302645885"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BMI500]",
   "language": "python",
   "name": "conda-env-BMI500-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
